% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sus_data_read.R
\name{sus_data_read}
\alias{sus_data_read}
\title{Read Processed Health Data with Batch and Parallel Support}
\usage{
sus_data_read(
  path,
  format = NULL,
  parallel = FALSE,
  workers = 4,
  read_metadata = FALSE,
  lang = "pt",
  verbose = TRUE
)
}
\arguments{
\item{path}{Character vector of file paths, or a single directory path.
If a directory is provided, all matching files will be read.}

\item{format}{Character string specifying the input format. Options: \code{"dbf"},
\code{"rds"}, \code{"parquet"}, \code{"geoparquet"}, \code{"shapefile"}, \code{"gpkg"}, \code{"geojson"}, \code{"csv"}.
If \code{NULL} (default), automatically detects format from file extension.}

\item{parallel}{Logical. If \code{TRUE}, uses parallel processing for multiple files.
Requires \code{future} and \code{future.apply} packages. Default: \code{FALSE}.}

\item{workers}{Integer. Number of parallel workers when \code{parallel = TRUE}. Default: 4.}

\item{read_metadata}{Logical. If \code{TRUE} (default), loads companion metadata files
and attaches them as attributes.}

\item{lang}{Character string specifying the language for messages. Options:
\code{"en"} (English), \code{"pt"} (Portuguese, default), \code{"es"} (Spanish).}

\item{verbose}{Logical. If \code{TRUE} (default), prints progress and summary.}
}
\value{
A data frame or sf object (for spatial data) containing the loaded data.
For batch reads, all files are combined with \code{dplyr::bind_rows()}.
Metadata is attached as attributes:
\itemize{
\item Single file: \code{attr(df, "metadata")}
\item Batch: \code{attr(df, "batch_metadata")} (list of metadata from each file)
\item Batch: \code{attr(df, "n_files_combined")} (number of files)
}
}
\description{
Intelligently reads one or multiple health data files exported by \code{sus_data_export()}.
Supports automatic format detection, batch processing, parallel execution, spatial data,
metadata loading, and data validation.
}
\details{
\strong{Batch Processing}:
Pass a vector of file paths or a directory path to read multiple files at once.
All files are automatically combined into a single object.

\strong{Parallel Processing}:
When \code{parallel = TRUE}, files are read simultaneously using \code{future.apply}.
This significantly speeds up batch reads of large files.

\strong{Format Detection}:
Automatically detects format from file extension. For \code{.parquet} files,
automatically determines if it's GeoParquet (spatial) or regular Parquet.

\strong{Memory Efficiency}:
For very large datasets (>50 GB), consider using chunked processing or
reading files individually instead of batch mode.
}
\examples{
\dontrun{
library(climasus4r)

# Single file
df <- sus_data_read("output/data.parquet")

# Multiple files (vector)
df <- sus_data_read(c("output/2020.parquet", "output/2021.parquet"))

# Directory (all Parquet files)
df <- sus_data_read("output/", format = "parquet")

# Parallel batch read
df <- sus_data_read("output/", format = "dbf", 
                    parallel = TRUE, workers = 6)

# Access batch metadata
batch_meta <- attr(df, "batch_metadata")
n_files <- attr(df, "n_files_combined")
}

}
